{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 20:58:37.936598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743022717.950264    4112 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743022717.955512    4112 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743022717.967056    4112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743022717.967084    4112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743022717.967086    4112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743022717.967087    4112 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-26 20:58:37.970175: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score   \n",
    "\n",
    "import bloqade \n",
    "from bloqade.ir.location import Chain, start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "y_train: (60000,)\n",
      "X_test: (10000, 28, 28)\n",
      "y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Download the MNIST dataset    \n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "train_X, test_X = train_X / 255.0, test_X / 255.0\n",
    "\n",
    "N_TRAIN = train_X.shape[0]\n",
    "N_TEST = test_X.shape[0]\n",
    "\n",
    "# Training dataset is 60000 images of 28x28 pixels\n",
    "print(f\"X_train: {train_X.shape}\")\n",
    "print(f\"y_train: {train_y.shape}\")\n",
    "\n",
    "# Test dataset is 10000 images of 28x28 pixels\n",
    "print(f\"X_test: {test_X.shape}\")\n",
    "print(f\"y_test: {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show example of image for 5\n",
    "plt.imshow(train_X[0], cmap='gray', interpolation='none')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training set PCA: \n",
      "    \n",
      "    [[ 0.48601015  1.22617358  0.09613354  2.17944297 -0.10704576  0.9116717\n",
      "   0.91763033  0.62666468]\n",
      " [ 3.96752304  1.15630211 -2.33858651  1.80692626 -3.24421656  0.71353148\n",
      "  -0.17655089 -0.41164546]\n",
      " [-0.2033318  -1.53793393  0.73925392 -2.04318175 -1.20266952  0.00719743\n",
      "  -3.36881255  1.44545833]\n",
      " [-3.13383152  2.38116556 -1.07314212 -0.41520877 -0.00726755 -2.74374391\n",
      "  -1.85769884 -0.2640067 ]\n",
      " [-1.50099977 -2.86487399 -0.06413234  0.94783341  0.38494646 -0.16952834\n",
      "  -0.35947686 -1.59041131]]\n",
      "    \n",
      "\n",
      "    Test set PCA:\n",
      "    \n",
      "    [[-1.30302419 -2.93254399  0.1680189   1.22028985 -1.9425927  -0.95048011\n",
      "   1.54080817  1.84606135]\n",
      " [ 0.08116456  3.74739052  0.59888438 -1.56344059 -0.19987208  1.84491363\n",
      "   1.09549373  0.90745685]\n",
      " [-3.70990929  1.68958111 -0.25951504 -1.02001031 -2.09448647 -0.34464815\n",
      "  -0.09418466 -0.4312494 ]\n",
      " [ 4.83885093 -0.44290373 -0.99533214  0.38530635 -0.81798657  1.90399072\n",
      "   2.72785227  0.29909493]\n",
      " [ 0.74226735 -2.80227973  1.14474942 -2.47579612 -0.58587542 -0.8807091\n",
      "  -1.94280463  0.92921276]]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Use PCA to downsample the data into 8-dimensional vectors\n",
    "dim_pca = 8\n",
    "\n",
    "# Define PCA model\n",
    "pca = PCA(n_components=dim_pca)\n",
    "\n",
    "# The PCA requires the input to be 2D, so we make an array with 60_000 rows and 784 columns\n",
    "reshaped_train_X = np.reshape(train_X, (N_TRAIN, 28*28))\n",
    "\n",
    "# Fit the PCA model to the training data\n",
    "pca.fit(reshaped_train_X)\n",
    "\n",
    "# Transform the training data using the fitted PCA model\n",
    "x_train = pca.transform(reshaped_train_X)\n",
    "\n",
    "# Display the training set\n",
    "num_train_examples = 1000\n",
    "num_test_examples = 200\n",
    "xs_train = x_train[\n",
    "        :num_train_examples,  # Rows up to num_examples\n",
    "        :               # All columns\n",
    "    ]\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Training set PCA: \n",
    "    \n",
    "    {xs_train[0:5, :]}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Same process for the test set\n",
    "reshaped_test_X = np.reshape(test_X, (N_TEST, 28*28))\n",
    "x_test = pca.transform(reshaped_test_X)\n",
    "\n",
    "# Display the test set\n",
    "xs_test = x_test[\n",
    "            :num_test_examples,  # Rows up to num_examples\n",
    "            :               # All columns\n",
    "        ]\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Test set PCA:\n",
    "    \n",
    "    {xs_test[0:5, :]}\n",
    "    \"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the range of principal components to a feasible range for local detuning implementation - [0, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral is the maximum difference between any two points in the dataset\n",
    "# It is used to determine the range of the data\n",
    "spectral = (np.amax(xs_train) - np.amin(xs_train))\n",
    "\n",
    "mn = np.amin(xs_train)\n",
    "xs_train = (xs_train - mn) / spectral   # The values range from 0 to 1\n",
    "xs_test = (xs_test - mn) / spectral     # The values range from 0 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Quantum Tasks and Simulate Dynamics\n",
    "\n",
    "We need to:  \n",
    "- Define a dictionary to capture the physical parameters and readouts of the quantum system\n",
    "- Define the functions that simulate quantum dynamics or build tasks that can be submitted to hardware with the input x from scaled detunings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_chain = Chain(dim_pca, lattice_spacing=10) # Linear chain of atoms with 10 microns between them\n",
    "\n",
    "QRC_parameters={\n",
    "    \"atom_number\": dim_pca,         # Number of atoms (dimension of the PCA space)\n",
    "    \"geometry_spec\": atom_chain,    # Geometry of the atoms\n",
    "    \"encoding_scale\": 9.0,          # Scaling factor for local detuning encoding\n",
    "    \"rabi_frequency\": 6.283,        # Value of the Rabi frequency used\n",
    "    \"total_time\": 4,                # Total maximum evolution time - 4 microseconds\n",
    "    \"time_steps\": 8,              # Number of probe times for quantum embedding collection (number of times it's measured during evolution) - 8 in the 4 microsecond window\n",
    "    \"readouts\": \"ZZ\"                 # Includes both ZZ correlators together (measures the correlations between the states of pairs of atoms in the system) with default Rydberg density as generated embeddings\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Function to Process QRC Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_task import build_task, process_results\n",
    "\n",
    "\n",
    "def get_embeddings_emulation(xs, num_examples, n_shots=1000):\n",
    "    \"\"\"\n",
    "        Function to get the embeddings from the quantum task\n",
    "\n",
    "        Input: \n",
    "            xs: Training set\n",
    "            num_examples: Number of examples to process\n",
    "            n_shots: Number of shots for the quantum task\n",
    "    \n",
    "        Output:\n",
    "            np.array with the embeddings of the training set\n",
    "    \"\"\"    \n",
    "    return np.array(\n",
    "        [\n",
    "            process_results(\n",
    "                # Dictionary with the QRC parameters\n",
    "                QRC_parameters=QRC_parameters, \n",
    "                \n",
    "                # Report of the quantum task\n",
    "                report=build_task( # Returns job ready to be run \n",
    "                    # Dictionary with the QRC parameters\n",
    "                    QRC_parameters, \n",
    "                    # Training set (iterating over every example)\n",
    "                    xs[data, :]\n",
    "                )\n",
    "                # Take the job and run it, returning the report\n",
    "                .bloqade.python().run(\n",
    "                    shots=n_shots, \n",
    "                    rtol=1e-8, \n",
    "                    atol=1e-8\n",
    "                )\n",
    "                .report()\n",
    "            )\n",
    "            \n",
    "            for data in range(num_examples)        \n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Simulation\n",
    "\n",
    "For each image, the readouts from the quantum dynamics will be a 288-dimensional vector, which has a mich higher dimenstion than the previous 8-dimension PCA.  \n",
    "\n",
    "The results are stored in a 1000x288 matrix called train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 288)\n",
      "(200, 288)\n",
      "\n",
      "    Train embeddings:\n",
      "    \n",
      "    [[-0.626  0.048 -0.13  ...  0.058  0.214 -0.1  ]\n",
      " [-0.126 -0.036 -0.382 ...  0.148  0.11   0.058]\n",
      " [-0.694 -0.308  0.02  ...  0.084  0.274  0.13 ]\n",
      " [-0.746  0.126 -0.246 ...  0.156  0.162  0.13 ]\n",
      " [-0.744 -0.432 -0.096 ...  0.154  0.202  0.06 ]]\n",
      "    \n",
      "\n",
      "    Test embeddings:\n",
      "    \n",
      "    [[-0.69  -0.428 -0.096 ...  0.14   0.302  0.19 ]\n",
      " [-0.698  0.294 -0.072 ...  0.02   0.104  0.032]\n",
      " [-0.744  0.078 -0.16  ...  0.238  0.302  0.212]\n",
      " [ 0.08  -0.198 -0.236 ...  0.234 -0.03  -0.304]\n",
      " [-0.554 -0.418  0.024 ...  0.19   0.322  0.208]]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "train_embeddings = get_embeddings_emulation(\n",
    "    xs=xs_train, \n",
    "    num_examples=num_train_examples, \n",
    "    n_shots=1000\n",
    ")\n",
    "\n",
    "test_embeddings = get_embeddings_emulation(\n",
    "    xs=xs_test, \n",
    "    num_examples=num_test_examples, \n",
    "    n_shots=1000\n",
    ")\n",
    "\n",
    "print(train_embeddings.shape)\n",
    "print(test_embeddings.shape)\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Train embeddings:\n",
    "    \n",
    "    {train_embeddings[0:5, :]}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Test embeddings:\n",
    "    \n",
    "    {test_embeddings[0:5, :]}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network to Evaluate Performance\n",
    "\n",
    "We are going to train a classical neural network without hidden layers (a linear classificer with softmax output function), using quantum measurements stored in embeddings as the input.\n",
    "\n",
    "For comparison, we will also train a neural network without hidden layers directly using PCA feature vectors without the quantum reservoir processing, as well as a simple neural network with two hidden layers for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743023517.448751    4112 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4088 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743023517.960558    7090 service.cc:152] XLA service 0x7f68f0006720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743023517.960576    7090 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5\n",
      "2025-03-26 21:11:57.970125: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743023518.009472    7090 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "I0000 00:00:1743023518.358252    7090 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Linear test accuracy: 68.0%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# 1) Linear classifier applied to PCA features\n",
    "\n",
    "# Build the linear model \n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Dense(10) # 10 output neurons (10 classes)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fitting to training data\n",
    "model.fit(\n",
    "    x=xs_train[:num_train_examples],\n",
    "    y=train_y[:num_train_examples],\n",
    "    epochs=1000,\n",
    "    batch_size=100, \n",
    "    verbose=0 \n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    x=xs_test, \n",
    "    y=test_y[:num_test_examples], \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"PCA Linear test accuracy: {100*round(test_acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-Layer NN test accuracy: 80.0%\n"
     ]
    }
   ],
   "source": [
    "# 2) Classical neural network with two hidden layers\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(50, activation='relu'),   # 50 neurons in the hidden layer\n",
    "        tf.keras.layers.Dense(50, activation='relu'),   # 50 neurons in the hidden layer \n",
    "        tf.keras.layers.Dense(10)                       # 10 output neurons (10 classes)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=xs_train,\n",
    "    y=train_y[:num_train_examples],\n",
    "    epochs=1000,\n",
    "    batch_size=100, \n",
    "    verbose=0 \n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    x=xs_test, \n",
    "    y=test_y[:num_test_examples], \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"4-Layer NN test accuracy: {100*round(test_acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QRC test accuracy: 82.0%\n"
     ]
    }
   ],
   "source": [
    "# 3) Linear classifier on quantum embeddings from the QRC\n",
    "# We include regularization and tune epsilon parameter to better control training from QRC embeddings generated on finite number of samples\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            10, \n",
    "            kernel_regularizer=tf.keras.regularizers.L1(l1=0.0001) # Regularization to avoid overfitting  \n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(epsilon=0.0002), # Epsilon parameter to better control training\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=train_embeddings,\n",
    "    y=train_y[:num_train_examples],\n",
    "    epochs=2000,\n",
    "    batch_size=100, \n",
    "    verbose=0 \n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    x=test_embeddings, \n",
    "    y=test_y[:num_test_examples], \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"QRC test accuracy: {100*round(test_acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have an implementation of the same process as before but with a SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuno/python_envs/quAI/lib/python3.11/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear PCA SVM test accuracy: 70.0%\n",
      "SVC test accuracy (rbf kernel): 89.0 %\n",
      "Linear QRC SVM test accuracy: 80.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuno/python_envs/quAI/lib/python3.11/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Just Linear PCA SVM\n",
    "svm = LinearSVC(C=1.0, multi_class='crammer_singer', dual=False)\n",
    "svm.fit(xs_train, train_y[:num_train_examples])\n",
    "y_pred = svm.predict(xs_test)\n",
    "accuracy = accuracy_score(test_y[:num_test_examples], y_pred)\n",
    "print(f\"Linear PCA SVM test accuracy: {100*round(accuracy, 2)}%\")\n",
    "\n",
    "# PCA SVM with RBF kernel\n",
    "svm = SVC(C=8.)\n",
    "svm.fit(xs_train, train_y[:num_train_examples])\n",
    "y_pred = svm.predict(xs_test)\n",
    "accuracy=svm.score(xs_test, test_y[:num_test_examples])\n",
    "print('SVC test accuracy (rbf kernel):', 100*round(accuracy, 2), \"%\")\n",
    "\n",
    "# Linear QRC SVM\n",
    "svm = LinearSVC(C=1.0, multi_class='crammer_singer', dual=False)\n",
    "svm.fit(train_embeddings, train_y[:num_train_examples])\n",
    "y_pred = svm.predict(test_embeddings)\n",
    "accuracy = accuracy_score(test_y[:num_test_examples], y_pred)\n",
    "print(f\"Linear QRC SVM test accuracy: {100*round(accuracy, 2)}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
