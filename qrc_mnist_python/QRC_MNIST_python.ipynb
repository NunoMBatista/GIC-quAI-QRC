{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 15:27:53.646698: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-26 15:27:53.647776: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-26 15:27:53.651284: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-26 15:27:53.660132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-26 15:27:53.680969: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-26 15:27:53.681002: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-26 15:27:53.694774: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-26 15:27:54.666464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score   \n",
    "\n",
    "import bloqade \n",
    "from bloqade.ir.location import Chain, start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "y_train: (60000,)\n",
      "X_test: (10000, 28, 28)\n",
      "y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Download the MNIST dataset    \n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "train_X, test_X = train_X / 255.0, test_X / 255.0\n",
    "\n",
    "N_TRAIN = train_X.shape[0]\n",
    "N_TEST = test_X.shape[0]\n",
    "\n",
    "# Training dataset is 60000 images of 28x28 pixels\n",
    "print(f\"X_train: {train_X.shape}\")\n",
    "print(f\"y_train: {train_y.shape}\")\n",
    "\n",
    "# Test dataset is 10000 images of 28x28 pixels\n",
    "print(f\"X_test: {test_X.shape}\")\n",
    "print(f\"y_test: {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJEElEQVR4nO3cOWhV6x7G4bWvwULRSBoFQUQLRUVsVDgIIiIiaBG1CVgpVgpWNnYWEcGhCFqkCtiIpUOjhVMhCOLQBOyVdBqNM5p9m8vLKS7c/Ne5GYzPU6+XtRCyf3yFX6fb7XYbAGia5l+z/QEAzB2iAECIAgAhCgCEKAAQogBAiAIAIQoARM9UH+x0OtP5HQBMs6n8X2UnBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAome2PwD+lwULFpQ3vb290/Al/x8nT55stVu0aFF5s27duvLmxIkT5c3FixfLm4GBgfKmaZrm27dv5c358+fLm7Nnz5Y384GTAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4EG+eWbVqVXmzcOHC8uavv/4qb3bs2FHeNE3TLFu2rLw5dOhQq3fNN2/evClvhoaGypv+/v7yZmJiorxpmqZ59epVefPo0aNW7/oTOSkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoARKfb7Xan9GCnM93fwt9s2bKl1e7+/fvlTW9vb6t3MbMmJyfLm6NHj5Y3nz59Km/aGBsba7V7//59efP69etW75pvpvJz76QAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQLgldY7q6+trtXv69Gl5s2bNmlbvmm/a/NuNj4+XN7t27SpvmqZpfvz4Ud64AZe/c0sqACWiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAETPbH8A/927d+9a7U6fPl3e7N+/v7x58eJFeTM0NFTetPXy5cvyZs+ePeXN58+fy5uNGzeWN03TNKdOnWq1gwonBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYDodLvd7pQe7HSm+1uYJUuXLi1vJiYmypvh4eHypmma5tixY+XNkSNHypvr16+XN/A7mcrPvZMCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQPTM9gcw+z5+/Dgj7/nw4cOMvKdpmub48ePlzY0bN8qbycnJ8gbmMicFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAKLT7Xa7U3qw05nub2GeW7x4cavd7du3y5udO3eWN/v27Stv7t27V97AbJnKz72TAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4EI85b+3ateXN8+fPy5vx8fHy5sGDB+XNs2fPypumaZqrV6+WN1P88+YP4UI8AEpEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAgX4jEv9ff3lzcjIyPlzZIlS8qbts6cOVPeXLt2rbwZGxsrb/g9uBAPgBJRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAMKFePAfmzZtKm8uX75c3uzevbu8aWt4eLi8GRwcLG/evn1b3jDzXIgHQIkoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOFCPPgHli1bVt4cOHCg1btGRkbKmzZ/t/fv3y9v9uzZU94w81yIB0CJKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEW1LhN/H9+/fypqenp7z5+fNnebN3797y5uHDh+UN/4xbUgEoEQUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAg6rdlwTy1efPm8ubw4cPlzdatW8ubpml3uV0bo6Oj5c3jx4+n4UuYDU4KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOFCPOa8devWlTcnT54sbw4ePFjerFixoryZSb9+/SpvxsbGypvJycnyhrnJSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgXIhHK20ughsYGGj1rjaX261evbrVu+ayZ8+elTeDg4Plza1bt8ob5g8nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYBwId48s3z58vJmw4YN5c2VK1fKm/Xr15c3c93Tp0/LmwsXLrR6182bN8ubycnJVu/iz+WkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4JXUG9PX1lTfDw8Ot3rVly5byZs2aNa3eNZc9efKkvLl06VJ5c/fu3fLm69ev5Q3MFCcFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgPijL8Tbvn17eXP69OnyZtu2beXNypUry5u57suXL612Q0ND5c25c+fKm8+fP5c3MN84KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDEH30hXn9//4xsZtLo6Gh5c+fOnfLm58+f5c2lS5fKm6ZpmvHx8VY7oM5JAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACA63W63O6UHO53p/hYAptFUfu6dFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGA6Jnqg91udzq/A4A5wEkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGA+DdFFDZD3G7ZOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show example of image for 5\n",
    "plt.imshow(train_X[0], cmap='gray', interpolation='none')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training set PCA: \n",
      "    \n",
      "    [[ 0.48601015  1.22617358  0.09613354  2.17944297 -0.10704576  0.9116717\n",
      "   0.91763033  0.62666468]\n",
      " [ 3.96752304  1.15630211 -2.33858651  1.80692626 -3.24421656  0.71353148\n",
      "  -0.17655089 -0.41164546]\n",
      " [-0.2033318  -1.53793393  0.73925392 -2.04318175 -1.20266952  0.00719743\n",
      "  -3.36881255  1.44545833]\n",
      " [-3.13383152  2.38116556 -1.07314212 -0.41520877 -0.00726755 -2.74374391\n",
      "  -1.85769884 -0.2640067 ]\n",
      " [-1.50099977 -2.86487399 -0.06413234  0.94783341  0.38494646 -0.16952834\n",
      "  -0.35947686 -1.59041131]]\n",
      "    \n",
      "\n",
      "    Test set PCA:\n",
      "    \n",
      "    [[-1.30302419 -2.93254399  0.1680189   1.22028985 -1.9425927  -0.95048011\n",
      "   1.54080817  1.84606135]\n",
      " [ 0.08116456  3.74739052  0.59888438 -1.56344059 -0.19987208  1.84491363\n",
      "   1.09549373  0.90745685]\n",
      " [-3.70990929  1.68958111 -0.25951504 -1.02001031 -2.09448647 -0.34464815\n",
      "  -0.09418466 -0.4312494 ]\n",
      " [ 4.83885093 -0.44290373 -0.99533214  0.38530635 -0.81798657  1.90399072\n",
      "   2.72785227  0.29909493]\n",
      " [ 0.74226735 -2.80227973  1.14474942 -2.47579612 -0.58587542 -0.8807091\n",
      "  -1.94280463  0.92921276]]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Use PCA to downsample the data into 8-dimensional vectors\n",
    "dim_pca = 8\n",
    "\n",
    "# Define PCA model\n",
    "pca = PCA(n_components=dim_pca)\n",
    "\n",
    "# The PCA requires the input to be 2D, so we make an array with 60_000 rows and 784 columns\n",
    "reshaped_train_X = np.reshape(train_X, (N_TRAIN, 28*28))\n",
    "\n",
    "# Fit the PCA model to the training data\n",
    "pca.fit(reshaped_train_X)\n",
    "\n",
    "# Transform the training data using the fitted PCA model\n",
    "x_train = pca.transform(reshaped_train_X)\n",
    "\n",
    "# Display the training set\n",
    "num_train_examples = 1000\n",
    "num_test_examples = 200\n",
    "xs_train = x_train[\n",
    "        :num_train_examples,  # Rows up to num_examples\n",
    "        :               # All columns\n",
    "    ]\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Training set PCA: \n",
    "    \n",
    "    {xs_train[0:5, :]}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Same process for the test set\n",
    "reshaped_test_X = np.reshape(test_X, (N_TEST, 28*28))\n",
    "x_test = pca.transform(reshaped_test_X)\n",
    "\n",
    "# Display the test set\n",
    "xs_test = x_test[\n",
    "            :num_test_examples,  # Rows up to num_examples\n",
    "            :               # All columns\n",
    "        ]\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Test set PCA:\n",
    "    \n",
    "    {xs_test[0:5, :]}\n",
    "    \"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the range of principal components to a feasible range for local detuning implementation - [0, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral is the maximum difference between any two points in the dataset\n",
    "# It is used to determine the range of the data\n",
    "spectral = (np.amax(xs_train) - np.amin(xs_train))\n",
    "\n",
    "mn = np.amin(xs_train)\n",
    "xs_train = (xs_train - mn) / spectral   # The values range from 0 to 1\n",
    "xs_test = (xs_test - mn) / spectral     # The values range from 0 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Quantum Tasks and Simulate Dynamics\n",
    "\n",
    "We need to:  \n",
    "- Define a dictionary to capture the physical parameters and readouts of the quantum system\n",
    "- Define the functions that simulate quantum dynamics or build tasks that can be submitted to hardware with the input x from scaled detunings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_chain = Chain(dim_pca, lattice_spacing=10) # Linear chain of atoms with 10 microns between them\n",
    "\n",
    "QRC_parameters={\n",
    "    \"atom_number\": dim_pca,         # Number of atoms (dimension of the PCA space)\n",
    "    \"geometry_spec\": atom_chain,    # Geometry of the atoms\n",
    "    \"encoding_scale\": 9.0,          # Scaling factor for local detuning encoding\n",
    "    \"rabi_frequency\": 6.283,        # Value of the Rabi frequency used\n",
    "    \"total_time\": 4,                # Total maximum evolution time - 4 microseconds\n",
    "    \"time_steps\": 8,              # Number of probe times for quantum embedding collection (number of times it's measured during evolution) - 8 in the 4 microsecond window\n",
    "    \"readouts\": \"ZZ\"                 # Includes both ZZ correlators together (measures the correlations between the states of pairs of atoms in the system) with default Rydberg density as generated embeddings\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Function to Process QRC Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_task import build_task, process_results, get_embeddings_emulation\n",
    "\n",
    "\n",
    "def get_embeddings_emulation(xs, num_examples, n_shots=1000):\n",
    "    \"\"\"\n",
    "        Function to get the embeddings from the quantum task\n",
    "\n",
    "        Input: \n",
    "            xs: Training set\n",
    "            num_examples: Number of examples to process\n",
    "            n_shots: Number of shots for the quantum task\n",
    "    \n",
    "        Output:\n",
    "            np.array with the embeddings of the training set\n",
    "    \"\"\"    \n",
    "    return np.array(\n",
    "        [\n",
    "            process_results(\n",
    "                # Dictionary with the QRC parameters\n",
    "                QRC_parameters=QRC_parameters, \n",
    "                \n",
    "                # Report of the quantum task\n",
    "                report=build_task( # Returns job ready to be run \n",
    "                    # Dictionary with the QRC parameters\n",
    "                    QRC_parameters, \n",
    "                    # Training set (iterating over every example)\n",
    "                    xs_train[data, :]\n",
    "                )\n",
    "                # Take the job and run it, returning the report\n",
    "                .bloqade.python().run(\n",
    "                    shots=n_shots, \n",
    "                    rtol=1e-8, \n",
    "                    atol=1e-8\n",
    "                )\n",
    "                .report()\n",
    "            )\n",
    "            \n",
    "            for data in range(num_examples)        \n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Simulation\n",
    "\n",
    "For each image, the readouts from the quantum dynamics will be a 288-dimensional vector, which has a mich higher dimenstion than the previous 8-dimension PCA.  \n",
    "\n",
    "The results are stored in a 1000x288 matrix called train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings_emulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_train_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m test_embeddings \u001b[38;5;241m=\u001b[39m get_embeddings_emulation(\n\u001b[1;32m      8\u001b[0m     xs\u001b[38;5;241m=\u001b[39mxs_test, \n\u001b[1;32m      9\u001b[0m     num_examples\u001b[38;5;241m=\u001b[39mnum_test_examples, \n\u001b[1;32m     10\u001b[0m     n_shots\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_embeddings\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[7], line 155\u001b[0m, in \u001b[0;36mget_embeddings_emulation\u001b[0;34m(xs, num_examples, n_shots)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    Function to get the embeddings from the quantum task\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m        np.array with the embeddings of the training set\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# # Get output size of a single example to determine the size of the embeddings\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# test_task = build_task(QRC_parameters, xs[0, :])\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# test_run = test_task.bloqade.python().run(shots=n_shots, rtol=1e-8, atol=1e-8)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# return embeddings\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m--> 155\u001b[0m     \u001b[43m[\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocess_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Dictionary with the QRC parameters\u001b[39;49;00m\n\u001b[1;32m    158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mQRC_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQRC_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m            \u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Report of the quantum task\u001b[39;49;00m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Returns job ready to be run \u001b[39;49;00m\n\u001b[1;32m    162\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Dictionary with the QRC parameters\u001b[39;49;00m\n\u001b[1;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43mQRC_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Training set (iterating over every example)\u001b[39;49;00m\n\u001b[1;32m    165\u001b[0m \u001b[43m                \u001b[49m\u001b[43mxs_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Take the job and run it, returning the report\u001b[39;49;00m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbloqade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_shots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-8\u001b[39;49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m        \u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    178\u001b[0m )\n",
      "Cell \u001b[0;32mIn[7], line 173\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    Function to get the embeddings from the quantum task\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m        np.array with the embeddings of the training set\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# # Get output size of a single example to determine the size of the embeddings\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# test_task = build_task(QRC_parameters, xs[0, :])\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# test_run = test_task.bloqade.python().run(shots=n_shots, rtol=1e-8, atol=1e-8)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# return embeddings\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    155\u001b[0m     [\n\u001b[1;32m    156\u001b[0m         process_results(\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;66;03m# Dictionary with the QRC parameters\u001b[39;00m\n\u001b[1;32m    158\u001b[0m             QRC_parameters\u001b[38;5;241m=\u001b[39mQRC_parameters, \n\u001b[1;32m    159\u001b[0m             \n\u001b[1;32m    160\u001b[0m             \u001b[38;5;66;03m# Report of the quantum task\u001b[39;00m\n\u001b[1;32m    161\u001b[0m             report\u001b[38;5;241m=\u001b[39m\u001b[43mbuild_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Returns job ready to be run \u001b[39;49;00m\n\u001b[1;32m    162\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Dictionary with the QRC parameters\u001b[39;49;00m\n\u001b[1;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43mQRC_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Training set (iterating over every example)\u001b[39;49;00m\n\u001b[1;32m    165\u001b[0m \u001b[43m                \u001b[49m\u001b[43mxs_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Take the job and run it, returning the report\u001b[39;49;00m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbloqade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_shots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-8\u001b[39;49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m         \n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_examples)        \n\u001b[1;32m    177\u001b[0m     ]\n\u001b[1;32m    178\u001b[0m )\n",
      "File \u001b[0;32m~/python_envs/quAI/lib/python3.11/site-packages/bloqade/task/batch.py:189\u001b[0m, in \u001b[0;36mLocalBatch.report\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     geos\u001b[38;5;241m.\u001b[39mappend(task\u001b[38;5;241m.\u001b[39mgeometry)\n\u001b[1;32m    185\u001b[0m index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_tuples(\n\u001b[1;32m    186\u001b[0m     index, names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_number\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperfect_sorting\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_sequence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    187\u001b[0m )\n\u001b[0;32m--> 189\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m df\u001b[38;5;241m.\u001b[39msort_index(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    192\u001b[0m rept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/python_envs/quAI/lib/python3.11/site-packages/pandas/core/frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m         arrays,\n\u001b[1;32m    861\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m     )\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/python_envs/quAI/lib/python3.11/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/python_envs/quAI/lib/python3.11/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/python_envs/quAI/lib/python3.11/site-packages/pandas/core/internals/construction.py:945\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m--> 945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_object_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m contents, columns\n",
      "File \u001b[0;32m~/python_envs/quAI/lib/python3.11/site-packages/pandas/core/internals/construction.py:1070\u001b[0m, in \u001b[0;36mconvert_object_array\u001b[0;34m(content, dtype, dtype_backend, coerce_float)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             arr \u001b[38;5;241m=\u001b[39m maybe_cast_to_datetime(arr, dtype)\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[0;32m-> 1070\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays\n",
      "File \u001b[0;32m~/python_envs/quAI/lib/python3.11/site-packages/pandas/core/internals/construction.py:1070\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             arr \u001b[38;5;241m=\u001b[39m maybe_cast_to_datetime(arr, dtype)\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[0;32m-> 1070\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m content]\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays\n",
      "File \u001b[0;32m~/python_envs/quAI/lib/python3.11/site-packages/pandas/core/internals/construction.py:1030\u001b[0m, in \u001b[0;36mconvert_object_array.<locals>.convert\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(arr):\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1030\u001b[0m         arr \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m            \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtry_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert_to_nullable_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumpy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;66;03m# Notes on cases that get here 2023-02-15\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m         \u001b[38;5;66;03m# 1) we DO get here when arr is all Timestamps and dtype=None\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;66;03m# 2) disabling this doesn't break the world, so this must be\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m         \u001b[38;5;66;03m#    getting caught at a higher level\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;66;03m# 3) passing convert_non_numeric to maybe_convert_objects get this right\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;66;03m# 4) convert_non_numeric?\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32mlib.pyx:2840\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_embeddings = get_embeddings_emulation(\n",
    "    xs=xs_train, \n",
    "    num_examples=num_train_examples, \n",
    "    n_shots=1000\n",
    ")\n",
    "\n",
    "test_embeddings = get_embeddings_emulation(\n",
    "    xs=xs_test, \n",
    "    num_examples=num_test_examples, \n",
    "    n_shots=1000\n",
    ")\n",
    "\n",
    "print(train_embeddings.shape)\n",
    "print(test_embeddings.shape)\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Train embeddings:\n",
    "    \n",
    "    {train_embeddings[0:5, :]}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Test embeddings:\n",
    "    \n",
    "    {test_embeddings[0:5, :]}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network to Evaluate Performance\n",
    "\n",
    "We are going to train a classical neural network without hidden layers (a linear classificer with softmax output function), using quantum measurements stored in embeddings as the input.\n",
    "\n",
    "For comparison, we will also train a neural network without hidden layers directly using PCA feature vectors without the quantum reservoir processing, as well as a simple neural network with two hidden layers for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1) Linear classifier applied to PCA features\n",
    "\n",
    "# Build the linear model \n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Dense(10) # 10 output neurons (10 classes)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fitting to training data\n",
    "model.fit(\n",
    "    x=xs_train[:num_train_examples],\n",
    "    y=train_y[:num_train_examples],\n",
    "    epochs=1000,\n",
    "    batch_size=100, \n",
    "    verbose=0 \n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    x=xs_test, \n",
    "    y=test_y[:num_test_examples], \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"PCA Linear test accuracy: {100*round(test_acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Classical neural network with two hidden layers\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(50, activation='relu'),   # 50 neurons in the hidden layer\n",
    "        tf.keras.layers.Dense(50, activation='relu'),   # 50 neurons in the hidden layer \n",
    "        tf.keras.layers.Dense(10)                       # 10 output neurons (10 classes)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=xs_train,\n",
    "    y=train_y[:num_train_examples],\n",
    "    epochs=1000,\n",
    "    batch_size=100, \n",
    "    verbose=0 \n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    x=xs_test, \n",
    "    y=test_y[:num_test_examples], \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"4-Layer NN test accuracy: {100*round(test_acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Linear classifier on quantum embeddings from the QRC\n",
    "# We include regularization and tune epsilon parameter to better control training from QRC embeddings generated on finite number of samples\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            10, \n",
    "            kernel_regularizer=tf.keras.regularizers.L1(l1=0.0001) # Regularization to avoid overfitting  \n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compilse(\n",
    "    optimizer=tf.keras.optimizers.Adam(epsilon=0.0002), # Epsilon parameter to better control training\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=train_embeddings,\n",
    "    y=train_y[:num_train_examples],\n",
    "    epochs=1000,\n",
    "    batch_size=100, \n",
    "    verbose=0 \n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    x=test_embeddings, \n",
    "    y=test_y[:num_test_examples], \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"QRC test accuracy: {100*round(test_acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have an implementation of the same process as before but with a SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just Linear PCA SVM\n",
    "svm = LinearSVC(C=1.0, multi_class='crammer_singer', dual=False)\n",
    "svm.fit(xs_train, train_y[:num_train_examples])\n",
    "y_pred = svm.predict(xs_test)\n",
    "accuracy = accuracy_score(test_y[:num_test_examples], y_pred)\n",
    "print(f\"Linear PCA SVM test accuracy: {100*round(accuracy, 2)}%\")\n",
    "\n",
    "# PCA SVM with RBF kernel\n",
    "svm = SVC(C=8.)\n",
    "svm.fit(xs_train, train_y[:num_train_examples])\n",
    "y_pred = svm.predict(xs_test)\n",
    "accuracy=svm.score(xs_test, test_y[:num_test_examples])\n",
    "print('SVC test accuracy (rbf kernel):', 100*round(accuracy, 2), \"%\")\n",
    "\n",
    "# Linear QRC SVM\n",
    "svm = LinearSVC(C=1.0, multi_class='crammer_singer', dual=False)\n",
    "svm.fit(train_embeddings, train_y[:num_train_examples])\n",
    "y_pred = svm.predict(test_embeddings)\n",
    "accuracy = accuracy_score(test_y[:num_test_examples], y_pred)\n",
    "print(f\"Linear QRC SVM test accuracy: {100*round(accuracy, 2)}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
